name: Research Audit

on:
  schedule:
    - cron: "0 15 * * 1" # Every Monday 15:00 UTC
  workflow_dispatch:
    inputs:
      seed:
        description: "Random seed for synthetic benchmarks"
        required: false
        default: "42"
      n_per_bucket:
        description: "Quotes per strike/maturity bucket for model-zoo benchmark"
        required: false
        default: "1"
      fail_on_arbitrage:
        description: "Fail workflow when no-arbitrage checks do not pass"
        required: false
        type: boolean
        default: true
      min_short_max_jump_reduction:
        description: "Minimum avg max-jump reduction required on short maturities"
        required: false
        default: "0.005"
      quotes_json:
        description: "Optional fixed quote fixture path for model-zoo benchmark"
        required: false
        default: "validation_scripts/fixtures/model_zoo_quotes_seed42.json"

concurrency:
  group: research-audit-${{ github.ref }}
  cancel-in-progress: true

jobs:
  research-audit:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    env:
      SEED: ${{ github.event_name == 'workflow_dispatch' && inputs.seed || '42' }}
      N_PER_BUCKET: ${{ github.event_name == 'workflow_dispatch' && inputs.n_per_bucket || '1' }}
      FAIL_ON_ARBITRAGE: ${{ github.event_name == 'workflow_dispatch' && inputs.fail_on_arbitrage || 'true' }}
      MIN_SHORT_MAX_JUMP_REDUCTION: ${{ github.event_name == 'workflow_dispatch' && inputs.min_short_max_jump_reduction || '0.005' }}
      QUOTES_JSON: ${{ github.event_name == 'workflow_dispatch' && inputs.quotes_json || 'validation_scripts/fixtures/model_zoo_quotes_seed42.json' }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run IV surface stability audit
        run: |
          EXTRA_FLAGS=""
          if [ "$FAIL_ON_ARBITRAGE" = "true" ]; then
            EXTRA_FLAGS="--fail-on-arbitrage"
          fi
          python validation_scripts/iv_surface_stability_report.py \
            --seed "$SEED" \
            --min-short-max-jump-reduction "$MIN_SHORT_MAX_JUMP_REDUCTION" \
            $EXTRA_FLAGS \
            --output-md artifacts/iv-surface-stability-report.md \
            --output-json artifacts/iv-surface-stability-report.json

      - name: Run rough-jump experiment
        run: |
          python validation_scripts/rough_jump_experiment.py --seed "$SEED" \
            > artifacts/rough-jump-experiment.txt

      - name: Run model-zoo benchmark
        run: |
          CMD_ARGS=(--seed "$SEED" --n-per-bucket "$N_PER_BUCKET")
          if [ -n "$QUOTES_JSON" ]; then
            CMD_ARGS=(--quotes-json "$QUOTES_JSON")
          fi
          python validation_scripts/pricing_model_zoo_benchmark.py \
            "${CMD_ARGS[@]}" \
            > artifacts/pricing-model-zoo-benchmark.txt

      - name: Publish report summary
        if: always()
        run: |
          if [ -f artifacts/iv-surface-stability-report.md ]; then
            cat artifacts/iv-surface-stability-report.md >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload research audit artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: research-audit-artifacts
          path: |
            artifacts/iv-surface-stability-report.md
            artifacts/iv-surface-stability-report.json
            artifacts/rough-jump-experiment.txt
            artifacts/pricing-model-zoo-benchmark.txt
